# 観察重視アプローチ{#empirics}
## 本章の概要

本章では \@ref(design) 章で紹介した観察重視（EF）アプローチについて紹介する。EFアプローチは、Golder et al. (2023）によって整理されたマーケティングにおける研究アプローチである。本書のこれまでの内容は、理論重視（TF）の研究アプローチに基づき構成されていた。TFアプローチはマーケティングにおける主流な研究法である。しかしながら、近年のデータ入手可能性の拡大や分析手法の洗練化によって、データ分析から探索的にマーケティングに関する知見を得る方法も無視できない重要なアプローチになった。しかしながら、EFアプローチはTFアプローチとは根本的に異なる目的とプロセスによって実施される必要がある。

本章では、（1）EFアプローチの概要、（2）EFアプローチによる研究プロセス、（3）EFアプローチに基づく研究紹介、（4）簡易的なデータ探索例を紹介する。特に、（4）のデータ探索例では、統計的な分析を用いずに顧客に関する洞察を得る方法を紹介する。EFアプローチ研究では珍しいフィールドデータと先端的分析手法とを用いる研究が目立つ。しなしながら、Golder et al. (2023) でも強調されているようにEFアプローチ研究における分析は簡単なデータ整理や分析から始めることが重要である。そこで本書では、Rを用いてデータを整理・処理することで、複雑な統計分析を行わなくてもマーケティング的知見を得られることを、顧客関係管理を例に紹介する。

## 観察重視アプローチ

EFは、現実のマーケティング事象、問題や観測に関するデータの取得と分析により、マーケティングに関するインサイトを得ることを目的とした研究アプローチである。データのアクセス可能性や分析手法の拡張により、現実のデータを入手し、探索的なぶんせきを行うことで、何らかの知見を得ることが可能になった。しかしながら実際にはこのようなアプローチをとっているにも関わらず、通常のTFアプローチ的な構成（イントロダクション $\rightarrow$理論・概念フレームワーク$\rightarrow$仮説$\rightarrow$方法$\rightarrow$結果$\rightarrow$ディスカッション）で論文を書くことは、疑わしい研究慣行として問題視されている。特に、HARKing（hypothesizing after the results are known）と言われる「結果を得てから仮説を作る」行為には注意が必要である。EFアプローチによって探索的なデータ分析を行った場合には、途中からTFに変更したり、装ったりすることはせず、EFアプローチとして研究を完遂し報告することが求められる。以下の表は、Golder et al. (2023, p.322) に記載されているTFとEFの対比を日本語訳したものである。

```{r tfvsef, warning=FALSE,message=FALSE,echo=FALSE}
library(tidyverse)

# データフレームの作成
ef_table <- data.frame(
  `研究プロセスのステップ` = c("理論のテストまたは開発", "研究の焦点の決定", "研究プロセスの認識", "研究プロセスの混乱への寛容さ", 
                              "文献レビュー", "原因究明", "事前のまとめ", "概念的枠組みの開発", "データ収集", "データ分析","頑健性のチェック", "頑健性が満たされない場合の判断", "原稿の執筆"),
  `TFアプローチ` = c("主要な目的", "研究は仮説に基づいた結果を中心に展開される", "直線的", "明快で内的一貫性があり、仮説を支持するような結果が期待される", 
                   "検証可能な仮説を支持するためのストーリーラインを提供", "焦点が絞られている", "より厳密", "事前に構成要素と関係性を明確に構築する", 
                   "理論/仮説を検証するための経験的証拠の収集", "仮説を評価するために統計的な分析を用いる", "代替理論や説明論理を排除することに重点を置く：着目する調査の範囲内で頑健性がチェックされる", 
                   "核心的な主張の信頼性を低下させる", "標準的なテンプレートが存在する"),
  `EFアプローチ` = c("数ある結果の可能性のうちの一つ", "探索的思考での研究", "反復的", "混乱はよくあることで、資産になり得る。また、混乱は十分に活用され報告されるべきである", 
                   "先行研究がなくても構わないが、洞察やインスピレーションを与えてくれる文献があればなお良い", "複数の角度からの説明が推奨される", "より拡散的", 
                   "構成概念とその関係性はゆるくつながれている：途中で概念枠組みが構築される可能性もある", "着目する事象について探求し理解するための経験的観察結果の収集", "有意でない結果も含め、経験的な結果を記述・報告する。",
                   "複数の説明論理や結果の差異を容認", "学習機会と見なす", "提案されるテンプレート: 現象に着目することへのモチベーション、さまざまな分析過程を説明し、得られたインサイトを述べる：理論的な示唆があることもあれば、ないこともある。")
)

# 表の表示

knitr::kable(ef_table, align = c('l','c','c'), caption = "TFとEFアプローチの研究の違い（Golder et al. (2023, p.322）より筆者訳")
```

上記のように、研究に関する様々な側面においてTFとEF間の違いが確認できる。研究プロジェクトやその目的によって適したアプローチは異なるため、各研究にそったアプローチを採用し、自身の用いたアプローチを明確に記述することが求められる。

## 観察重視アプローチの研究プロセス
Golder et al.（2023）は、論文内でEFアプローチに基づく研究プロセスも紹介している。具体的には、EF研究は主に以下の３つの段階を経る形で実施される。

- 研究機会の特定
- 地形探索
- 理解の発展

本節では、これらの要素について説明を行うことで、EFアプローチを実施するための基本的な考え方を共有する。

### 研究機会の特定
EFアプローチの研究を実行するために重要なことは、研究機会を発見し特定化することである。EF研究では、新興であり未開拓の現実の現象について分析を行うことが求められる。先入観を持たずに、実社会で起きているマーケティングやその他の事象から、既存の理論では説明できない問題や、マーケティングステークホルダー（例えば、消費者、実務家、政策決定者、教育機関など）が直面している問題や不都合を発見して捉えることが重要になる。

研究になりうる問題を捉えたら、その後、新しいデータソースを活用する必要がある。また、EF研究によって得た結果はマーケティングステークホルダーにとって活用可能であり、彼らの行動に直結するような示唆を含むことが求められる。そのため、データソースの選択においては、実行可能（主体が操作可能）な説明変数と結果に値する被説明変数の両方を捉える必要がある。

その後、EFアプローチを採用することの適切さを評価することが求められる。EFアプローチは以下の状況においては特に適当だと考えられる（Golder et al., 2023）。
- 理論の供給が不足している。
- 既存研究の知見が一貫していない。
- 直感的に、複数の相対するが尤もらしい帰結が予想される。
- 実世界やビジネスレポートによる観察が理論的予測と一貫していない。
- 経験的な発見（効果）の発生頻度については未検討である。
- 新しく豊かなデータへのアクセスによって未検討の関係性について探索できる。

これらの基準を満たす場合、EFに基づく研究を進め、次の段階として、データと思考を行き来するプロセスを繰り返すことになる。


### 地形探索
研究上の問いの設定は、EFアプローチにおいても踏襲すべき最初のステップである。しかしながら、EFアプローチの特徴は、初期に決めた問いからデータの収集及び分析を行った結果得た知見によって再度問いを考え直すことを許容し、推奨している（Golder et al., 2023）。そのため、データと思考の行き来することで、着目する領域についての地形を探索することが求められる。

EFアプローチに基づく研究は多くの場合探索的な問い（「ある領域における重要な要素はなにか？」や「どうなっているか？」）に基づき研究が始まる。そのため研究者が着目する事象についてわからないことも多く、研究の進捗に応じて当初設定した問いが修正されることもある。例えば、データを収集し分析を行うことで実情についての知見を得た結果、より広範で深い問いに直面することもあるだろう。その場合、新しい研究上の問いに着目することでより高次な知見につながるため、研究の範囲や問いは（再）検討されるという特徴を持つ。

データの収集及び分析はEFアプローチ研究における重要なプロセスである。研究者はデータの作成、接合や取得を通じて、自身が着目するユニークなデータセットを構築する必要がある。

データセットを構築した後はそれを分析するのだが、まずはシンプルなデータの確認や分析から始めることが推奨される。モデル化をしていない発見事項（Model-free evidence）によって重要な変数の特徴、変数間の関係について把握し、その後のモデルに基づく分析に移行することが期待される。データの可視化も有力なアプローチであり、テキストマイニング、クラスター分析（\@ref(cluster)章）や、因子分析（\@ref(factor)章）などによるデータ構造の単純化を伴う方法と組み合わせることで、有益な情報提示になりうる。そして、model-free evidence を得た後に、様々な頑健性のチェックや因果関係の検証を行い、より高度な批判に耐えうる分析結果を得ることが求められる。

分析を行った後、EFアプローチでは、得たデータや結果についての検討を行うことが、データ分析プロセス内で求められる。例えば、「新たなデータを利用することで結論が変わりそうか？」のような問題を検討することでデータおよび結果の信頼性について検討することはEFアプローチ研究の結果に関する信頼性を向上することにつながる。また、「発見事項が実務や社会的に洞察に富むものかどうか？」、「検出された効果量（effect size）が意味のあるものか？」ということについての検討も、有効な検討となりうる。その検討の結果、必要であれば問いの（再）検討に移行し、改めてデータ探索プロセスを繰り返す。一方でこれらの検討事項に基づ、追加的な検証が必要ないのではないかと判断された場合、データ探索を終了する。

### 理解の発展
データを探索することで得られた知見（観察結果、発見事項）に関する一般化可能性を検討することが求められる。EFアプローチによって観察された結果が、理論的、数学的、視覚的手法を用いて単純化された形で、他の文脈や環境においても繰り返される規則性の発見へつながることがある。その場合、EFによる発見物の貢献は大きい。また、その差異、効果の方向性（例えば、正負）だけでなく、効果量に関する規則性についても言及することができると、通常の理論的枠組みでは提供できない知見として、大きな社会的意義を持つことが期待される。

必須ではないとはいえ、EFアプローチによる研究でも新たな概念的、理論的含意を提供することはある。EFアプローチによる研究は現象に関するステークホルダーに関する行動可能な含意を重視するが、抽象化を行うことでより一般化可能なマーケティングに関する知見や理論的基盤の構築につながる。

### EFアプローチ研究の報告
EFアプローチ研究により得た結果を論文化する際には、いくつか注意すべき点が存在する。第一に、当該研究がEFアプローチによるものであることを明確に伝え、なぜそのアプローチが適切なのかを説明する必要がある。そのため、EFアプローチによって実行された研究をTFアプローチかのように整理し論文化することは避けるべきである。そのようなアプローチはHARKingとして不適切な研究態度と問題視される可能性がある。

しかし、一気通貫したプロセスではない研究過程を読者に伝えるのは困難である。そのため、EFアプローチの論文であっても、研究者が経験した全ての紆余曲折を記述する必要はない。しかしながら当該研究が持つ探索的な性質については反映した原稿を書く必要がある。例えば、論文の冒頭にフローチャートや論文の構造について明示し、それに沿った節構成や図表を採用することで、読み手の労力を下げるような工夫が求められる。

そのうえで、論文内で伝える内容は発見事項に誠実である必要があり、過度な一般化や根拠のない実務的含意の提供は避けなければならない。当該研究の発見を超えた一般化や実務的含意については、その後に続く別研究により達成されるべきである。また、Appendixなどを使って詳細な経験的発見物を共有することも重要である。このような知見をきちんと構造化して提示することは後続の研究（特に、メタ分析など）にとって有意義な情報となり、学術的貢献を持つ。

## EFアプローチ研究例

ここでは、EFアプローチ研究の例として、Chung et al. (2022) を紹介する。Chung et al. (2022) は、消費者がオンラインホームシェアプラットフォームに着目し、シェアリングエコノミーにホストととして参加する動機にどのようなものがあるか、そして動機の違いがゲストの満足度やホストの生涯価値の変化をどう説明できるかを分析した研究である。著者らは、Airbnbのデータを用いて、13,337人のホストから得たテキスト回答を分析し、ホストの動機を明らかにした。その後、291,746件の予約取引に関する情報を抽出し、動機により結果変数（ゲストの満足度やホストの生涯価値）がどのように変わるかを分析した。

消費者の動機は、非常に素朴かつ重要な情報でありながら、その調査困難性からあまり研究において着目されてこなかった経緯がある。近年では、プラットフォームやマーケットプレイスを通じて消費者が自身の所有物を他者に貸し出すような行動が見られるようになった。このような活動はシェアリングエコノミーをと呼ばれ、その市場規模も拡大している。

シェアリングエコノミーという新しい消費・取引形態の重要性が実務的にも学術的にも増す一方で、消費者の動機に関する未開拓な状況は引き続いていた。消費者による財の供給者（ホストなど）としてのシェアリングエコノミーへの参加については、様々な動機が考えられる。そして消費者がどのような動機でプラットフォームに参加するのかは、重要な問いになりうる。その理由は、参加動機が異なる場合、プラットフォーム上での振る舞い（提供する情報）に違いが生まれる可能性があり、ひいては受容者（ゲストなど）の満足度や供給者の得る成果にも影響を与えるかもしれない。しかしながら、この点について先行研究では十分に検討されてこなかった。

この問題に対して Chung et al. (2022) は、Airbnb という代表的なオンラインシェアリングエコノミープラットフォームであり、物件（部屋や建物）を共有するサービスにおける2種類のデータセットを用いて探索した。1つ目は、Airbnb上で実際のユーザーに対して行った調査データである。具体的には、2013年3月から2014年10月までの期間に渡ってAibnbのホストに対してサイト上で表示された自由回答式設問（なぜホスティングを始めたのですか？"Why did you start hosting?"）への回答（テキストデータ） 13,337件を用いた。2つ目のデータはAirbnb内における 291,746件の予約取引に関するデータ（予約日、宿泊数、人数、価格、ゲストのレビューレーティング、物件に関する詳細な情報）である。

ホストの動機を明らかにするため、著者らは自由回答で得たアンケートデータに対し、機械学習におけるマルチラベル学習（multi-label classification）トピックモデル（topic model）を用いることで複数の動機を抽出した。発見された動機は（1）現金を稼ぐ、（2）美しさを共有する、（3）人々と出会う、（4）状況依存（空室を持つなど）、（5）Paying forward、（6）他者からの紹介、（7）その他、であった。そのため、ホストの動機として金銭的な動機と内的な動機（美しさや出会い）が存在することが大規模なフィールドデータから明らかになった。また、これらの動機は具体的なテキストデータから抽出された頻出ワードからラベリングされたものであるため、これらの概念に対応するワードも同時に確認されている。

2つ目のデータセットにおける分析では、ホストの初期エンゲージメント（Airbnb プラットフォームに参加する時点での、物件についての記載内容における文字や写真の数）を計測した。また、上記の動機の抽出で見つかったワード（美しさの共有や、人々との出会い）を使い、内的な動機をもったホストを特定し、動機の違いによるホストのエンゲージメントに関する違いを分析した。分析においてはまず model-free evidenceとして平均の差の検定を行い、内的な動機を持つホストはエンゲージメントが高い一方で、金銭的な動機を持つホストはエンゲージメントの程度が低いことを明らかにした。この結果をより生地に検証するために筆者らは、様々なコントロール変数を用いた回帰分析を行った。結果として、内的な動機を持つホストはエンゲージメントが高いという結果については一貫した結果を得ている。

また、筆者らはシナリオを用いた消費者実験を行うことでこの結果の妥当性を検証した。実験の参加者にはランダムに異なる動機を含むシナリオを提示され、その後彼/彼女らはある物件をAirbnbで貸し出すための広告文章を書いた。なお、物件に関しては全ての参加者を通じて共通である。つまり、実験的にランダムに操作（提示）された動機よって物件に関する記載が変化するかを確認するデザインになっている。実験により得たデータを分析した結果、金銭的な動機に直面した場合に比べ、美しさの共有や人々との出会いといった動機に直面した被験者はより多くの文字数を用いることが確認された。つまり、動機の違いによるエンゲージメントの程度については実験的な操作を通じても再現される規則性を持った結果である可能性が高い。その後 Chung et al. (2022)では、Airbnb内の予約取引データを用いて、動機 $\rightarrow$ エンゲージメント$\rightarrow$ ゲストの満足度（星5評価レビューの比率）という媒介関係を確認した。

また、同論文内ではBayesian laten attribution model を用いて、動機がAirbnb内での活動パターンと生存（掲示物件の残存）へ与える影響も分析している。その結果、人々と会うためという動機を持つホストは、それ以外のホストと比べ、解約傾向が低く予約泊数が多い一方で、一泊あたりの価格は低いということがわかった。美しさの共有という動機を持つホストは予約泊数は低いものの価格は高いという結果であったものの、解約傾向については有意な結果を得られなかった。金銭的な動機を持つホストでは有意に低い価格が設定されるが、予約泊数や解約傾向については有意な結果が得られなかった。予約傾向について高い傾向を持つホストは状況依存による動機を持つであった。

このように Chung et al. (2022) ではリッチなフィールドデータおよび実験調査と様々な先端的分析手法を組み合わせることで、シェアリングエコノミーにおけるホストの動機と、それらの動機のプラットフォーム内での活動や成果との関係について明らかにした。

## 簡易的なデータ探索法紹介：統計的分析を用いない顧客分析

### データ処理と顧客関係管理（CRM）{#crm}
前節で紹介したように、EFアプローチ研究では珍しいフィールドデータと先端的分析手法とを用いる研究が目立つ。Chung et al. (2022) で扱ったような分析手法は本書の範囲を超えるため扱わない。しなしながら、Golder et al. (2023) でも強調されているようにEFアプローチ研究における分析は簡単なデータ整理や分析から始めることが重要である。

そこで本節では、Rを用いてデータを整理・処理することで、複雑な統計分析を行わなくてもマーケティング的知見を得られることを、顧客関係管理を例に紹介する。

### データの構造変化とソート
本節では、学術的に価値を持つような広範な影響力を持つEFアプローチ研究ではなく、特定の企業における主要顧客を発見することを目的とした探索的分析例を紹介する。

現代のマーケティングリサーチでは、顧客の購買データを用いて（統計的な分析を要さず）重要顧客や顧客層を発見することが、小売企業を中心に広く行われている。ここでは基本的に、ID-POSデータを用いたデータベースの正規化と集計2焦点を合わせ、そのための分析手法を紹介する。特に、顧客個人に関する情報を用いながら企業や店舗にとって重要な顧客を特定し、その顧客との関係性を深めた場合を考える。

小売企業や店舗の運営効率から考えると、単に来店客数を増やすだけでなく、より頻繁に、より高額の買い物をする顧客を特定し、その人（達）の購買を促進することが効果的になる。言い換えると、企業や店舗は、ロイヤルカスタマーを特定し、その顧客との関係性を構築したいと考えるのである。そのためにはまず、ロイヤルカスタマーを特定する作業が必要になる。そこで本節では、データから企業にとって価値のある顧客を発見する方法について、データの前処理技術を応用する形で紹介する。

本節では簡単に、単純なデータハンドリングから顧客インサイトを得る方法を考える。特に、データ処理とソーティング（順番の入れ替え）を用いる方法を用いる。本節ではID-POSデータを用いた分析として、デシル分析とRFM分析を紹介する。デシル分析は、支出額をもとに上位から顧客を並べ替え、その順番に基づき顧客を10分割することで、上位の支出額を担うランクに属する顧客を特定する。なお、他の指標で同様の分析を実行することも可能だが、一般的には支出額を用いることが多い。例えば、月当たり5000人の顧客がいるとすると、500人ずつのグループに分け、購買額の大きい順にデシル1〜10 (10〜1の場合もある) とする形でランク分けする方法がこれにあたる。このとき、各顧客の情報がポイントカードやアプリで紐付いているのであれば、最も購買額の多いグループの特徴を整理することで、現在購入額の高い顧客がどんな特徴を持つのか理解できる。

一方、RFM（Recency, Frequency, Monetary）分析は、取引情報から、最近いつ買ったか、どれだけの頻度で買い物するか、どれだけ支出しているかといった情報を総合的に勘案し、どの顧客が最重要かを特定する方法である。これらの指標は、ロイヤルティや再購買確率が高い顧客を判別するのに役立つ3つの指標である。例えば、最終購買日から時間が経っている顧客は離反しているかもしれないし、購買頻度や購買額が高いと、ロイヤルティが高い可能性が高い。また、クーポンや割引利用の有無の情報と紐付けることができれば、当該顧客がチェリーピッカーか否かも判断することができる。

ID-POSデータは、各顧客の会員IDについての情報はありながらも取引ベースで情報が整理されている。このようなデータに対して以下の手順を用いてデータを集計・ソーティングする。

1. 顧客IDごとに、各取引情報を集計する。
2. 顧客ID情報についてまとめたデータベースにおける順番をソートし、重要顧客を識別する。

このようなデータの集計は、データ構造を取引ベースから顧客IDベースに変換することを可能にする。下図は、取引ベースのID-POSデータを、集計作業によって顧客IDベースのデータ構造に変換するイメージを示したものである。ID-POSデータは、顧客ID情報が含まれていながらも、データの行（観測）は各取引を示している。そのため、仮に同じIDの顧客がデータ収集期間に複数回取引を行っている場合、同じIDを含む観測がいくつも見られることになる。一方で下部の顧客IDベースのデータは、ID-POSデータを顧客ID情報によって集計したものであり、一定期間中に特定のIDを持つ顧客がどのような購買行動を示していたかを捉えたデータである。そのため、データの行は各顧客IDを示している。本節では、まずはじめにこのようなデータ構造の変換について説明する。


![データ構造変化](datahandling/datastructure.png){width=70%}

ここでは、先程利用した idpos データを用いて作業を進める。改めて、当該データを以下のコマンドで確認する。

```{r}
idpos <- readr::read_csv("data/2022idpos.csv", na = ".")
head(idpos)
```

ここで、date変数を用いて直近で何日前の来店かを示す変数を作成する。このデータは、2019年09月01日 から 2019年10月01日までの一ヶ月間、とある店舗で記録された取引データであると仮定し作成されている。そのため、データ収集終了最新時点（2019-10-2）と来店日時の差を表す変数を作成する (ここでの処理にエラーが出る場合は、`idpos$date <- as.Date(idpos$date)` というコマンドを事前に試してから変数の定義を行ってほしい)。head関数により出力された結果によって新たな変数（datediff）が追加されたことがわかる。

```{r datediff}
idpos$datediff<-
  as.numeric(difftime("2019-10-02",idpos$date,units="days"))
head(idpos)
```

続いて、パイプ演算子を使ったデータ処理によって顧客IDベースの形へ集計する。ここでは特に、group_by() という関数を使い、顧客id (今回は性別情報も残したいので gender も加えている)をグループ化の基準と指定する形で集計を行う。また、CRM分析で使う変数のために、idレベルでの集計という形で以下の変数を作成する。そして、以下の変数を用いて集計した新たなデータセットを "idpos_cust" として定義する。

- frequency：各idの出現頻度をn()でカウントする
- monetary：spentの合計をsum()で計算する
- cherry (picker)：クーポンの利用回数の合計をsum()で計算する
- recency：datediffの最小値をmin()で求め、直近でいつ来たかを判別


```{r idbased, message=FALSE}
idpos_cust <- idpos %>% 
  group_by(id) %>% 
  summarize(frequency = n(), 
            monetary = sum(spent), 
            cherry = sum(coupon), 
            recency = min(datediff)
            )
head(idpos_cust)
```

上記の操作によって、元々のidposデータから、顧客ベースのデータ構造（idpos_cust）に変換できたはずである。しかしこれだけでは、まだ我々は誰が重要顧客か特定できない。そのため、次に我々はデータの並べかえを行う。具体的には、支出額が高い順に並び替えたあとに上位20人の顧客を表示する。

```{r monetary}
idpos_cust_m <- idpos_cust %>% 
  arrange(desc(monetary))

##Customers in the top 20 (Monetary) 
idpos_cust_m[1:20,]

```

### データ結合

ここまでの結果からは購買額の高い顧客IDを特定することができた。しかしながら、これらの顧客がどのような特徴を持っているのかについては推察できない。そのため、別で管理されていた顧客情報を捉えたデータセットと結合することでこれらの顧客についての属性を把握する。
以下では、今回使用する顧客情報データセットを読み込み、その概要を示している。このデータセットには、3000人分の会員登録済み顧客情報が蓄積されており、以下の変数を含む：

- id: 顧客ID
- gender: 性別
- age: 年齢
- famsize: 世帯人数

```{r iddata,message=FALSE}
id_data <- readr::read_csv("data/id_data.csv", na = ".")
str(id_data)
```

ここで、顧客データと購買データを `left_join()` を用いて、`idpos_cust` をメインとする形で `id` によって結合する。`left_join()` は左側に指定したデータフレームに存在知するキーの行を返す形でデータの結合を行う。言い換えると、左側のデータセットに存在する行（観測）はすべて残され、そこに新たな変数を加える形でデータフレーム間の結合を行う。

```{r leftjoin}
idpos_cust <- left_join(idpos_cust,id_data, by = "id")
head(idpos_cust)
```

上記の通り、顧客ベースの取引情報に、各顧客の属性情報が追加された事がわかる。これを利用し、以下のように上位20顧客の性別比率を以下のように確認する。これによって、主要顧客に占める性別比率が確認できる。

```{r gender ratio}
idpos_cust_m <- idpos_cust %>% 
  arrange(desc(monetary))

#gender ratio in the top 20
table(idpos_cust_m[1:20,]$gender)
```


続いては先述のデシル分析を実行する。具体的には、idpos_custに対し、cut()関数を使うことで、monetaryの大きさに基づきサンプルを10等分し、新たに "decile_rank" という変数（列）をデータに追加し、その新たなデータセットを "idpos_cust_m"と定義する。なお、次節にてこのデータを改めて使うため、データをprojectのdataディレクトリ内に保存しておいてほしい。
```{r decile}
idpos_cust_m$decile_rank <- 
  cut(idpos_cust_m$monetary,
      quantile(idpos_cust_m$monetary, (0:10)/10,na.rm=TRUE),
      label=FALSE,include.lowest=TRUE)
head(idpos_cust_m)
readr::write_csv(idpos_cust_m, "data/idpos_customer.csv")
```
head()関数によって新たな変数の追加を確認したあとは、各デシルの店舗売上への貢献度を確認する。ここでは、decile_rankをグループ化の基準として設定し、summarize() によって集計する方法を用いる。その後、各デシルの売上比率を計算し、高い順に並び替える。集計・分析の結果は、上位20%の顧客で、ID-POSに計上されている売上の57%を締めていることを示した。

```{r decileshare}
decile <- idpos_cust_m %>% 
  group_by(decile_rank) %>% 
  summarize(freq = n(),
            monetary = sum(monetary)) 
total <- sum(decile$monetary)

decile2 <- decile %>% 
  mutate(percent = monetary/total*100) %>% 
  arrange(desc(decile_rank))

decile2
```

本節で示したように、高度な統計的分析を実行せずとも重要顧客を特定する事が可能になる。本節では特に、データの集計や処理技術を使った方法を紹介した。このような分析によって回答できる問いは「企業にとっての重要顧客は誰か」というものだろう。この問いは非常に興味深く実務的にも有意義なものであるが、以下の点に注意することが重要である。第一に、何をもって顧客の重要性を定義するかという問題である。本節では特にRFMなどの基準を用いて、観察可能な購買結果をもとに重要顧客を識別する方法を捉えた。しかしながら、例えば購買頻度と購買額では異なる側面を捉えており、どの指標を用いて分析するかによって（通常は）結果が異なる。そのため、研究者自身が「重要性」をどのように定義するのかを注意深く判断し、なおかつそれをレポートやプレゼンテーション内できちんと明示する必要がある。さらに、データでは捉えきれない側面は分析結果に反映されないという点についても注意が必要である。例えば日本には江戸時代から続く小売企業もいくつも存在する。仮に、そのような小売企業と、長期間代々取引を続けている顧客（一族や企業）がいたとして、さらにその顧客が分析による上位顧客に含まれなかったとする。その場合、この顧客を重要顧客でないと切り捨てて良いのでだろうか。災害、国家の統治体制の変化、戦争、などの激動を経てなお取引が続いている顧客は重要でないと言い切れるのだろうか。もちろん、このような顧客を重要でないと捉えることも、経営判断として間違ったものではない。しかしながら、少なくともデータを用いた分析結果を過信しすぎず、データによって何が捉えられており、何が捉えきれていないのかについて研究者・意思決定者のどちらも自覚的になることが必要になる。

第二に、分析を行うだけでマーケティング実務が完結するわけではないという点についても注意が必要である。「重要顧客を特定する」という研究課題の背後には、「CRMを実行して収益性を向上させる」という実務的課題が存在しているはずである。そのため、今回の発見物をもとに、マーケティング活動への示唆を与えていくことが重要になるのだが、誰が重要顧客か、という問いに答えるだけでは具体的な活動指針（アプリを通じた囲い込みや、訪問販売等）を与えるのは難しい。そのため、重要顧客のライフスタイルや価値観などの彼/彼女らの特徴に踏み込んだ調査を行うことも必要になるかもしれない。昨今のロイヤルティプログラム（ポイントシステム）では、モバイルアプリを通じて個人の様々な行動履歴が記録されたり、アンケートへの回答を促されたりすることがあるだろう。これらの情報とID-POSデータをうまく接合できれば、重要顧客を特定しつつ、それらの顧客に適したCRM方策を策定できるかもしれない。

## 参考文献
Chung, J., Johar, G. V., Li, Y., Netzer, O., Pearson, M., Inman, J. J., & Winer, R. S. (2022). Mining Consumer Minds: Downstream Consequences of Host Motivations for Home-Sharing Platforms. *Journal of Consumer Research*, 48(5), 817-838.

Golder, P. N., Dekimpe, M. G., An, J. T., van Heerde, H. J., Kim, D. S. U., & Alba, J. W. (2023). Learning from Data: An Empirics-First Approach to Relevant Knowledge Generation. *Journal of Marketing*, 87(3), 319-336.

